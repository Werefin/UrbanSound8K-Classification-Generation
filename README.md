# UrbanSound8K-Classification-Generation

## About this project

### Audio classification on UrbanSound8K dataset
CNN model that can classify 10 different sounds with a fairly high accuracy. The key is to use Mel-Frequency Cesptral Coefficients (MFCCs) to turn the audio points into a spatial representation.

### Audio generation using CVAE
Convolutional Variational Autoencoder (CVAE) implemented to denoise MFCCs vectors and generation of new data samples.

## Dependencies and setup
This requires the use of Jupyter Notebook. You can use either the Anaconda version or Google Colab to run this. Note that if you are using the local machine Anaconda version, you do need to install the necessary modules/dependencies to run this.

TensorFlow: https://www.tensorflow.org/install;

Librosa: https://librosa.org/doc/latest/install.html;

Numpy:https://numpy.org/install/;

MatPlotLib: https://matplotlib.org/stable/users/installing/index.html;

## Tools
Anaconda Jupyter Notebook: https://jupyter.org/;
Google Colab: https://colab.research.google.com/?utm_source=scs-index;
